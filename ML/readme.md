# ğŸ“„ Compte rendu â€“ Base de donnÃ©es *Wine Quality (White Wine)*

## ğŸ·ï¸ 1. PrÃ©sentation gÃ©nÃ©rale

La base de donnÃ©es *Wine Quality* (vin blanc) provient de lâ€™UCI Machine Learning Repository.  
Elle contient des mesures **physico-chimiques** de vins blancs portugais, ainsi quâ€™un **score de qualitÃ©** attribuÃ© par des experts.

Elle est destinÃ©e Ã  des tÃ¢ches de **rÃ©gression** (prÃ©dire la qualitÃ©) ou de **classification** (qualitÃ© bonne ou mauvaise).

---

## ğŸ“Š 2. Dimensions du dataset

Ã€ partir du chargement via `pandas` :

- **Nombre dâ€™Ã©chantillons :** 4 898  
- **Nombre de variables explicatives (features) :** 11  
- **Variable cible :** `quality` (entier de 0 Ã  10)

---

## ğŸ‡ 3. Variables disponibles

| Nom de la variable          | Description |
|-----------------------------|-------------|
| fixed acidity               | AciditÃ© fixe (acides non volatils) |
| volatile acidity            | AciditÃ© volatile (acide acÃ©tique) |
| citric acid                 | Acide citrique |
| residual sugar              | Sucres rÃ©siduels |
| chlorides                   | Chlorures |
| free sulfur dioxide         | SOâ‚‚ libre |
| total sulfur dioxide        | SOâ‚‚ total |
| density                     | DensitÃ© du vin |
| pH                          | Niveau dâ€™aciditÃ© pH |
| sulphates                   | Sulfates |
| alcohol                     | Teneur en alcool |
| quality (variable cible)    | Note de qualitÃ© (0â€“10) |

---

## ğŸ·ï¸ 4. PrÃ©paration du problÃ¨me de classification

La variable `quality` est initialement une note de 0 Ã  10.  
Le script construit un problÃ¨me de **classification binaire** :

- **Classe 0 â€“ vin de mauvaise qualitÃ©** : `quality â‰¤ 5`  
- **Classe 1 â€“ vin de bonne qualitÃ©** : `quality â‰¥ 6`

---

## ğŸ“ˆ 5. Analyse statistique initiale

Deux types dâ€™analyses ont Ã©tÃ© rÃ©alisÃ©es :

### ğŸ”¹ 5.1. BoÃ®tes Ã  moustaches (boxplots)

Elles permettent de visualiser :

- la distribution de chaque variable,
- les Ã©ventuels outliers,
- les diffÃ©rences dâ€™Ã©chelle entre les features.

### ğŸ”¹ 5.2. Matrice de corrÃ©lation

Le heatmap permet dâ€™observer :

- des corrÃ©lations fortes (ex. entre **density**, **residual sugar**, et **total sulfur dioxide**),
- des corrÃ©lations globalement faibles avec la variable cible.

---

## ğŸ” 6. Split des donnÃ©es

Le dataset est divisÃ© en trois sous-ensembles :

- **Train (â‰ˆ33%)**
- **Validation (â‰ˆ33%)**
- **Test (â‰ˆ33%)**

Le dÃ©coupage est :

- **stratifiÃ©** (conservation des proportions de classes),
- **shuffle** (mÃ©lange alÃ©atoire).

---

## ğŸ¤– 7. ModÃ¨le de classification : k-NN

Un classifieur **k-Nearest Neighbors (k-NN)** a Ã©tÃ© appliquÃ©.

### ğŸ”¹ Ã‰tapes :

1. Apprentissage pour diffÃ©rents `k` (1, 3, 5, ..., 35)
2. Calcul de :
   - lâ€™erreur dâ€™entraÃ®nement,
   - lâ€™erreur de validation
3. SÃ©lection du meilleur `k` (minimisant lâ€™erreur de validation)
4. Test sur le jeu de test

### Observations :

- **Overfitting** pour les petits `k` (1, 3â€¦)
- **Meilleure gÃ©nÃ©ralisation** pour des `k` modÃ©rÃ©s

---

## ğŸ”§ 8. Normalisation

Une normalisation **StandardScaler** a Ã©tÃ© effectuÃ©e :

- centrage des donnÃ©es (moyenne = 0),
- rÃ©duction (Ã©cart-type = 1).

Importance :

- indispensable pour k-NN car dÃ©pend des distances,
- doit Ãªtre ajustÃ©e **uniquement** sur le train, puis appliquÃ©e au validation/test.

---

## âœ… 9. Conclusion gÃ©nÃ©rale

Ce dataset est utile pour :

- lâ€™analyse exploratoire,
- la classification supervisÃ©e,
- lâ€™Ã©tude de lâ€™impact de la normalisation,
- la comprÃ©hension de lâ€™overfitting.

Le modÃ¨le k-NN montre que :

- La performance dÃ©pend fortement du choix de `k`
- La normalisation amÃ©liore sensiblement les rÃ©sultats
- La stratification est essentielle pour un split fiable

---


