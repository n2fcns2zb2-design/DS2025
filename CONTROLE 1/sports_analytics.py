# -*- coding: utf-8 -*-
"""sports analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wz8h2eB3CZhOpC6mflornx7OlZ1pdG0P
"""



"""# Task
Analyze the sports data from `ginf.csv`, `dictionary.txt`, and `archive.zip` by performing data cleaning, sports analysis, and regression analysis. Visualize the findings and provide a comprehensive study and evaluation of the insights gained.

## Load and Explore Data

### Subtask:
Load the `ginf.csv` file into a pandas DataFrame. Inspect its structure, data types, and first few rows to understand the dataset. Also, check the contents of `dictionary.txt` and `archive.zip` to determine if they contain additional relevant information for the sports analysis.

**Reasoning**:
First, I'll import the pandas library, load the `ginf.csv` file into a DataFrame, and then display the first 5 rows to get an initial understanding of the data.
"""

import pandas as pd

df_matches = pd.read_csv('/content/ginf.csv')
print("First 5 rows of ginf.csv:")
df_matches.head()

"""**Reasoning**:
Now that the `df_matches` DataFrame is loaded, I will inspect its structure and data types using `info()` and display descriptive statistics for numerical columns using `describe()` to get a better understanding of the data.


"""

print("\nDataFrame Info:")
df_matches.info()

print("\nDescriptive Statistics:")
df_matches.describe()

"""**Reasoning**:
To understand the contents of `dictionary.txt`, I will open and read the file.


"""

print("\nContents of dictionary.txt:")
with open('/content/dictionary.txt', 'r') as f:
    dictionary_content = f.read()
print(dictionary_content)

"""**Reasoning**:
To inspect the contents of `archive.zip` and identify any relevant files, especially CSV files, I will use Python's `zipfile` module to list the names of all files inside the archive.


"""

import zipfile

print("\nContents of archive.zip:")
with zipfile.ZipFile('/content/archive.zip', 'r') as zip_ref:
    zip_contents = zip_ref.namelist()
    for file_name in zip_contents:
        print(file_name)

    csv_files = [f for f in zip_contents if f.endswith('.csv')]
    if csv_files:
        print("\nCSV files found in archive.zip:")
        for csv_file in csv_files:
            print(csv_file)
    else:
        print("\nNo CSV files found in archive.zip.")

"""## Data Cleaning and Preparation

### Subtask:
Clean the loaded data by handling missing values, correcting inconsistencies, and converting data types as necessary. Prepare the dataset for sports analysis by creating any derived features that might be useful (e.g., goal differences, win/loss indicators).

**Reasoning**:
First, I'll load the `events.csv` file from `archive.zip` into a new DataFrame named `df_events`. Then, I'll display its first 5 rows to understand its structure.
"""

import zipfile

with zipfile.ZipFile('/content/archive.zip', 'r') as zip_ref:
    with zip_ref.open('events.csv') as f:
        df_events = pd.read_csv(f)

print("First 5 rows of df_events:")
df_events.head()

"""**Reasoning**:
Now that `df_events` is loaded, I will inspect its structure and data types using `info()` and display descriptive statistics for numerical columns using `describe()` to get a better understanding of the data. This addresses instructions 3 and 4.


"""

print("\nDataFrame Info for df_events:")
df_events.info()

print("\nDescriptive Statistics for df_events:")
df_events.describe()

"""**Reasoning**:
I will convert the 'date' column to datetime objects and then create new columns for 'goal_difference', 'total_goals', and 'match_outcome' in the `df_matches` DataFrame as specified in the instructions to prepare the data for further analysis.


"""

df_matches['date'] = pd.to_datetime(df_matches['date'])

df_matches['goal_difference'] = df_matches['fthg'] - df_matches['ftag']
df_matches['total_goals'] = df_matches['fthg'] + df_matches['ftag']

def get_match_outcome(row):
    if row['fthg'] > row['ftag']:
        return 'Home Win'
    elif row['ftag'] > row['fthg']:
        return 'Away Win'
    else:
        return 'Draw'

df_matches['match_outcome'] = df_matches.apply(get_match_outcome, axis=1)

print("df_matches after adding new features:")
df_matches.head()

"""## Map categorical codes to labels and handle missing values in df_events

### Subtask:
Parse the dictionary file to create mapping dictionaries and use them to convert numerical event codes in `df_events` to descriptive labels. Handle missing values in these newly mapped columns.

**Reasoning**:
I will first define a function to parse the `dictionary_content` string and create mapping dictionaries for each category. This function will be crucial for converting numerical event codes to descriptive labels as specified in the subtask.
"""

def parse_dictionary_content(dictionary_string):
    mappings = {}
    current_category = None
    for line in dictionary_string.split('\n'):
        line = line.strip()
        if not line:
            continue
        if '\t' not in line and line.isalpha(): # Category header (e.g., event_type)
            current_category = line
            mappings[current_category] = {}
        elif current_category and '\t' in line:
            parts = line.split('\t', 1)
            if len(parts) == 2:
                try:
                    key = int(parts[0])
                    value = parts[1].strip()
                    mappings[current_category][key] = value
                except ValueError:
                    # Handle cases where key is not an integer if necessary,
                    # but based on the dictionary structure, it should be an int
                    pass
    return mappings

dictionary_mappings = parse_dictionary_content(dictionary_content)
print("Parsed dictionary mappings:")
for category, mapping in dictionary_mappings.items():
    print(f"{category}: {mapping}")

"""**Reasoning**:
The previous `parse_dictionary_content` function had an issue correctly identifying categories and their corresponding mappings from the `dictionary.txt` content, leading to incorrect assignments. I will correct the parsing logic to accurately extract key-value mappings for each category (e.g., 'event_type', 'shot_place') and regenerate the `dictionary_mappings` to ensure proper data type conversion and descriptive labeling.


"""

def parse_dictionary_content(dictionary_string):
    mappings = {}
    blocks = dictionary_string.strip().split('\n\n') # Split by double newline to get category blocks

    for block in blocks:
        lines = [line.strip() for line in block.split('\n') if line.strip()]
        if not lines:
            continue

        category_name = lines[0]
        # Ensure category_name is not a key-value line itself (doesn't contain tab)
        if '\t' in category_name or not category_name:
            continue

        mappings[category_name] = {}
        for line in lines[1:]: # Process key-value pairs
            parts = line.split('\t', 1)
            if len(parts) == 2:
                try:
                    key = int(parts[0])
                    value = parts[1].strip()
                    mappings[category_name][key] = value
                except ValueError:
                    # This should not happen if dictionary format is consistent
                    pass
    return mappings

dictionary_mappings = parse_dictionary_content(dictionary_content)
print("Corrected Parsed dictionary mappings:")
for category, mapping in dictionary_mappings.items():
    print(f"{category}: {mapping}")

"""**Reasoning**:
Now that the `dictionary_mappings` are correctly parsed, I will use them to create new descriptive columns in `df_events` by mapping the numerical codes to their corresponding labels. I'll also handle missing values in these new columns by filling them with 'Unknown' or 'Not Recorded' as appropriate.


"""

columns_to_map = {
    'event_type': 'event_type_description',
    'event_type2': 'event_type2_description',
    'side': 'side_description',
    'shot_place': 'shot_place_description',
    'shot_outcome': 'shot_outcome_description',
    'location': 'location_description',
    'bodypart': 'bodypart_description',
    'assist_method': 'assist_method_description',
    'situation': 'situation_description'
}

for original_col, new_col in columns_to_map.items():
    if original_col in dictionary_mappings:
        # Convert column to float to ensure compatibility with NaN before mapping
        df_events[original_col] = df_events[original_col].astype(float)
        df_events[new_col] = df_events[original_col].map(dictionary_mappings[original_col])

        # Fill NaN values in the new descriptive column
        if new_col == 'event_type2_description':
            df_events[new_col] = df_events[new_col].fillna('Not Applicable')
        elif original_col in ['shot_place', 'shot_outcome', 'location', 'bodypart', 'situation']:
            df_events[new_col] = df_events[new_col].fillna('Unknown')
        elif original_col == 'assist_method':
             df_events[new_col] = df_events[new_col].fillna('Unknown') # Should mostly be 0 for None, but for consistency
    else:
        print(f"Warning: Mapping for '{original_col}' not found in dictionary_mappings.")


print("First 5 rows of df_events with new descriptive columns:")
df_events.head()

"""## Handle missing values in df_matches

### Subtask:
Address the missing values in the numerical columns of `df_matches`.

**Reasoning**:
I will calculate the median for the specified numerical columns with missing values and then fill these missing values with their respective medians. Finally, I'll display the DataFrame's info to confirm the missing values have been handled.
"""

columns_to_fill = ['odd_over', 'odd_under', 'odd_bts', 'odd_bts_n']

for col in columns_to_fill:
    if df_matches[col].isnull().any():
        median_value = df_matches[col].median()
        df_matches[col].fillna(median_value, inplace=True)
        print(f"Filled missing values in '{col}' with median: {median_value}")

print("\nDataFrame Info after handling missing values:")
df_matches.info()

"""**Reasoning**:
The previous code block generated a `FutureWarning` because `inplace=True` in `.fillna()` can lead to unexpected behavior when used with chained assignment. To fix this, I will modify the `fillna` operation to assign the result back to the column directly, ensuring the changes are applied correctly and the warning is resolved.


"""

columns_to_fill = ['odd_over', 'odd_under', 'odd_bts', 'odd_bts_n']

for col in columns_to_fill:
    if df_matches[col].isnull().any():
        median_value = df_matches[col].median()
        df_matches[col] = df_matches[col].fillna(median_value)
        print(f"Filled missing values in '{col}' with median: {median_value}")

print("\nDataFrame Info after handling missing values:")
df_matches.info()

"""## Conduct Sports Analysis

### Subtask:
Perform various sports-related analyses such as calculating team performance metrics (e.g., win rates, average scores) and exploring match outcomes by league and country.

**Reasoning**:
I will group the `df_matches` DataFrame by 'league' to calculate the counts of 'Home Win', 'Away Win', and 'Draw' outcomes, the total number of matches, and the average home and away goals for each league. This will allow for the computation of win and draw rates per league.
"""

league_analysis = df_matches.groupby('league').agg(
    home_wins=('match_outcome', lambda x: (x == 'Home Win').sum()),
    away_wins=('match_outcome', lambda x: (x == 'Away Win').sum()),
    draws=('match_outcome', lambda x: (x == 'Draw').sum()),
    total_matches=('match_outcome', 'count'),
    avg_fthg=('fthg', 'mean'),
    avg_ftag=('ftag', 'mean')
)

league_analysis['home_win_rate'] = (league_analysis['home_wins'] / league_analysis['total_matches']) * 100
league_analysis['away_win_rate'] = (league_analysis['away_wins'] / league_analysis['total_matches']) * 100
league_analysis['draw_rate'] = (league_analysis['draws'] / league_analysis['total_matches']) * 100

print("Sports Analysis by League:")
print(league_analysis[['home_win_rate', 'away_win_rate', 'draw_rate', 'avg_fthg', 'avg_ftag']].round(2))

"""**Reasoning**:
I will group the `df_matches` DataFrame by 'country' to calculate the counts of 'Home Win', 'Away Win', and 'Draw' outcomes, the total number of matches, and the average home and away goals for each country. This will allow for the computation of win and draw rates per country, similar to the league analysis.


"""

country_analysis = df_matches.groupby('country').agg(
    home_wins=('match_outcome', lambda x: (x == 'Home Win').sum()),
    away_wins=('match_outcome', lambda x: (x == 'Away Win').sum()),
    draws=('match_outcome', lambda x: (x == 'Draw').sum()),
    total_matches=('match_outcome', 'count'),
    avg_fthg=('fthg', 'mean'),
    avg_ftag=('ftag', 'mean')
)

country_analysis['home_win_rate'] = (country_analysis['home_wins'] / country_analysis['total_matches']) * 100
country_analysis['away_win_rate'] = (country_analysis['away_wins'] / country_analysis['total_matches']) * 100
country_analysis['draw_rate'] = (country_analysis['draws'] / country_analysis['total_matches']) * 100

print("\nSports Analysis by Country:")
print(country_analysis[['home_win_rate', 'away_win_rate', 'draw_rate', 'avg_fthg', 'avg_ftag']].round(2))

"""## Perform Regression Analysis

### Subtask:
Conduct a regression analysis to predict goal difference based on betting odds.

**Reasoning**:
First, I will import the necessary libraries for regression analysis, then select the specified columns from `df_matches` to create a new DataFrame, define the dependent and independent variables, and split the data into training and testing sets. This sets up the data for model training and evaluation.
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Select relevant columns for regression
df_regression = df_matches[['goal_difference', 'odd_h', 'odd_d', 'odd_a']].copy()

# Define dependent and independent variables
X = df_regression[['odd_h', 'odd_d', 'odd_a']]
y = df_regression['goal_difference']

# Split the data into training and testing sets (80/20 ratio)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Data split into training and testing sets successfully.")
print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"y_test shape: {y_test.shape}")

"""**Reasoning**:
Now that the data has been split into training and testing sets, I will initialize and train a Linear Regression model using the training data, then make predictions on the test set, and finally evaluate the model's performance by calculating and printing MAE, MSE, R2 score, and the model coefficients.


"""

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"\nMean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R2) Score: {r2:.2f}")

print("\nModel Coefficients:")
for feature, coef in zip(X.columns, model.coef_):
    print(f"{feature}: {coef:.2f}")
print(f"Intercept: {model.intercept_:.2f}")

"""## Visualize Findings and Regressions

### Subtask:
Generate a variety of plots and graphs to visualize the results of the sports analysis and regression models.

**Reasoning**:
I will generate the requested grouped bar charts for league and country analysis (win rates and average goals) and a scatter plot for actual vs. predicted goal difference, as specified in the instructions, using `matplotlib.pyplot` and `seaborn` for clear visualization.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Set plot style
sns.set_style("whitegrid")

# 1. Grouped bar chart for 'home_win_rate', 'away_win_rate', and 'draw_rate' by league
fig, axes = plt.subplots(3, 2, figsize=(18, 20))

league_analysis[['home_win_rate', 'away_win_rate', 'draw_rate']].plot(kind='bar', ax=axes[0, 0])
axes[0, 0].set_title('Win and Draw Rates by League')
axes[0, 0].set_xlabel('League')
axes[0, 0].set_ylabel('Rate (%)')
axes[0, 0].tick_params(axis='x', rotation=45)
axes[0, 0].legend(loc='best')

# 2. Grouped bar chart for 'avg_fthg' and 'avg_ftag' by league
league_analysis[['avg_fthg', 'avg_ftag']].plot(kind='bar', ax=axes[0, 1])
axes[0, 1].set_title('Average Goals by League')
axes[0, 1].set_xlabel('League')
axes[0, 1].set_ylabel('Average Goals')
axes[0, 1].tick_params(axis='x', rotation=45)
axes[0, 1].legend(loc='best')

# 3. Grouped bar chart for 'home_win_rate', 'away_win_rate', and 'draw_rate' by country
country_analysis[['home_win_rate', 'away_win_rate', 'draw_rate']].plot(kind='bar', ax=axes[1, 0])
axes[1, 0].set_title('Win and Draw Rates by Country')
axes[1, 0].set_xlabel('Country')
axes[1, 0].set_ylabel('Rate (%)')
axes[1, 0].tick_params(axis='x', rotation=45)
axes[1, 0].legend(loc='best')

# 4. Grouped bar chart for 'avg_fthg' and 'avg_ftag' by country
country_analysis[['avg_fthg', 'avg_ftag']].plot(kind='bar', ax=axes[1, 1])
axes[1, 1].set_title('Average Goals by Country')
axes[1, 1].set_xlabel('Country')
axes[1, 1].set_ylabel('Average Goals')
axes[1, 1].tick_params(axis='x', rotation=45)
axes[1, 1].legend(loc='best')

# 5. Scatter plot of actual vs. predicted goal difference
axes[2, 0].scatter(y_test, y_pred, alpha=0.3)
axes[2, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--') # Diagonal line
axes[2, 0].set_title('Actual vs. Predicted Goal Difference')
axes[2, 0].set_xlabel('Actual Goal Difference')
axes[2, 0].set_ylabel('Predicted Goal Difference')

# Remove unused subplot
fig.delaxes(axes[2,1])

plt.tight_layout()
plt.show()

"""## Final Task

### Subtask:
Provide a comprehensive study and evaluation of the sports data, summarizing key findings, insights from the analyses, and conclusions drawn from the visualizations and regression models.

## Summary:

### Data Analysis Key Findings

*   **Data Overview**: The dataset consists of `ginf.csv` (10,112 matches, 18 columns), `events.csv` (941,009 events, 22 columns), and `dictionary.txt` for mapping categorical data. `ginf.csv` contains match-level data including teams, scores, dates, and betting odds, with several odds columns initially showing significant missing values.
*   **Data Preparation**:
    *   The 'date' column in `df_matches` was converted to datetime objects.
    *   New features were successfully created in `df_matches`: `goal_difference`, `total_goals`, and `match_outcome` ('Home Win', 'Away Win', 'Draw').
    *   Missing values in `df_matches` betting odds columns (`odd_over`, `odd_under`, `odd_bts`, `odd_bts_n`) were imputed using their respective median values (e.g., `odd_over` with 2.03, `odd_bts` with 1.92).
    *   `dictionary.txt` was successfully parsed to map numerical event codes in `df_events` to descriptive labels. Missing values in these newly mapped descriptive columns were handled (e.g., 'Not Applicable' for `event_type2_description`, 'Unknown' for `shot_place_description`).
*   **Sports Analysis - League & Country Performance**:
    *   **League SP1 (Spain)** exhibited the highest home win rate at 47.73% and the highest average home goals at 1.63.
    *   **League F1 (France)** showed the lowest away win rate at 26.96% and the highest draw rate at 27.24%.
    *   These trends were consistent at the country level, with Spain mirroring SP1's strong home performance and France mirroring F1's lower away win and higher draw rates.
*   **Regression Analysis - Goal Difference Prediction**:
    *   A Linear Regression model was trained to predict goal difference using betting odds (`odd_h`, `odd_d`, `odd_a`).
    *   The model achieved a Mean Absolute Error (MAE) of 1.22, a Mean Squared Error (MSE) of 2.49, and an R-squared (R2) score of 0.20.
    *   The coefficient for `odd_h` was -0.21, suggesting that lower home odds (indicating a stronger favorite) are associated with a higher goal difference for the home team. Coefficients for `odd_d` (0.05) and `odd_a` (0.08) were positive but smaller.

### Insights or Next Steps

*   The R-squared score of 0.20 for the regression model indicates that while betting odds provide some predictive power for goal difference, a significant portion of the variance remains unexplained. Further analysis could incorporate more features (e.g., historical team performance, event statistics from `df_events`) to improve prediction accuracy.
*   The distinct patterns in win rates and average goals across different leagues and countries suggest varying playing styles or competitive balances. Investigating the factors contributing to these differences (e.g., team strengths, league structure, economic factors) could provide deeper insights into football dynamics.
"""